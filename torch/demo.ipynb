{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # tested with torch v1.13, python v1.9\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import distributions as dist\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing classes and functions for l-ACNF. See `l_acnf.py` script for their implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l_acnf import Lattice, l_ACNF, sample_fn, logprob_fn, train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize lattice, device and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice = Lattice(16, 5.0, True)\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "net = l_ACNF(8, 128).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model for given epochs, batchsize and learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 9000\n",
    "batch = 128\n",
    "train(lattice, net, batch, epochs, 2e-3, 1500, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or uncomment below cell and load pre-trained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"lacnf_d_8.pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import helper functions for Metropolis-Hastings sampling using the trained model. See `mc_sample.py` for implementation details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mc_sample import metropolis, greens_function, pole_mass, susceptibilty, ising_energy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_p_mean = torch.zeros([7])\n",
    "m_p_std = torch.ones([7])\n",
    "\n",
    "chi_2_mean = torch.zeros([7])\n",
    "chi_2_std = torch.ones([7])\n",
    "\n",
    "E_mean = torch.zeros([7])\n",
    "E_std = torch.ones([7])\n",
    "\n",
    "rej = []\n",
    "chi_1 = []\n",
    "chi_2 = []\n",
    "E = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate observables at every Monte Carlo step as well as their means and standard errors via moving block bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = [6.008, 5.55, 5.276, 5.113, 4.99, 4.89, 4.82]\n",
    "T = 100_000\n",
    "\n",
    "for (j,L) in enumerate(range(8, 21, 2)):\n",
    "    lattice = Lattice(L, g[j], True)\n",
    "    phi, r, c1, c2, e = metropolis(lattice, net, 2500, T, device)\n",
    "    \n",
    "    rej.append(r)\n",
    "    chi_1.append(c1)\n",
    "    chi_2.append(c2)\n",
    "    E.append(e)\n",
    "    \n",
    "    # Moving block bootstrap\n",
    "    bin = 100\n",
    "    boxes = [torch.arange(i, i+bin, device=device) \n",
    "            for i in range(T-bin+1)]\n",
    "    \n",
    "    m_p = []\n",
    "    chi_22 = torch.zeros([bin])\n",
    "    E2 = torch.zeros([bin])\n",
    "    \n",
    "    for n in range(bin):\n",
    "        r = np.random.randint(0, T-bin+1, (T//bin,))\n",
    "        indx = torch.cat([boxes[n] for n in r], dim=0)\n",
    "        \n",
    "        phi2 = phi[indx, :, :]\n",
    "        G = greens_function(phi2, device)\n",
    "        G2 = G.mean(1)\n",
    "        \n",
    "        m_p.append(pole_mass(G2))\n",
    "        chi_22[n] = susceptibilty(G)\n",
    "        E2[n] = ising_energy(G)\n",
    "    \n",
    "    m_p = torch.stack(m_p, dim=0)\n",
    "    m_p_mean[j] = m_p.mean(0)[1:].mean()*L\n",
    "    m_p_std[j] = m_p.std(0)[1:].mean()*L\n",
    "    \n",
    "    chi_2_mean[j] = chi_22.mean()\n",
    "    chi_2_std[j] = chi_22.std()\n",
    "    E_mean[j] = E2.mean()\n",
    "    E_std[j] = E2.std()\n",
    "\n",
    "rej = torch.stack(rej, dim=0)\n",
    "chi_1 = torch.stack(chi_1, dim=0)\n",
    "chi_2 = torch.stack(chi_2, dim=0)\n",
    "E = torch.stack(E, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m_p_mean, m_p_std) # Average Pole mass\n",
    "print(chi_2_mean, chi_2_std) # 2 point susceptibility\n",
    "print(E_mean, E_std) # Ising energy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate autocorrelation functions and times wrt acceptance statistics and various observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max = 100\n",
    "rho_acc = torch.zeros([rej.shape[0], t_max])\n",
    "for t in range(1, t_max+1):\n",
    "    pool_op = torch.nn.MaxPool1d(t, 1)\n",
    "    rho_acc[:, t-1] = (1-pool_op((1-rej).unsqueeze(1))).mean([1,2])\n",
    "t_int_acc = 0.5 + rho_acc.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_chi_1 = torch.zeros([chi_1.shape[0], t_max])\n",
    "rho_chi_2 = torch.zeros([chi_2.shape[0], t_max])\n",
    "rho_E = torch.zeros([E.shape[0], t_max])\n",
    "\n",
    "for t in range(1, t_max+1):\n",
    "    chi_1_mean2 = chi_1.mean(1, keepdim=True)\n",
    "    covar = (chi_1[:, :-t]-chi_1_mean2)*(chi_1[:, t:]-chi_1_mean2)\n",
    "    rho_chi_1[:, t-1] = covar.mean(1)/chi_1.var(1)\n",
    "    \n",
    "    chi_2_mean2 = chi_2.mean(1, keepdim=True)\n",
    "    covar = (chi_2[:, :-t]-chi_2_mean2)*(chi_2[:, t:]-chi_2_mean2)\n",
    "    rho_chi_2[:, t-1] = covar.mean(1)/chi_2.var(1)\n",
    "    \n",
    "    E_mean2 = E.mean(1, keepdim=True)\n",
    "    covar = (E[:, :-t]-E_mean2)*(E[:, t:]-E_mean2)\n",
    "    rho_E[:, t-1] = covar.mean(1)/E.var(1)\n",
    "\n",
    "t_int_chi_1 = 0.5 + rho_chi_1.sum(1)\n",
    "t_int_chi_2 = 0.5 + rho_chi_2.sum(1)\n",
    "t_int_E = 0.5 + rho_E.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rho_acc)\n",
    "print(t_int_acc) # Acceptance statistics\n",
    "\n",
    "print(rho_chi_1)\n",
    "print(t_int_chi_1) # G(0) or 1-point susceptibility\n",
    "\n",
    "print(rho_chi_1)\n",
    "print(t_int_chi_1) # 2-point susceptibility\n",
    "\n",
    "print(rho_E)\n",
    "print(t_int_E) # Ising energy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
